{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMMPVikhsb3XRhgLF+6vOr4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"0bb05a9288e447388546935dc9e297aa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7d855e4f146e4d1ba492a4e1ccb3b7b2","IPY_MODEL_2770311ddfe34125a6ecab641973cf5b","IPY_MODEL_26d085f232fa438babf3af19f7e55fc3"],"layout":"IPY_MODEL_993307cbf2bd4a9f8a7c00dbcd121f9c"}},"7d855e4f146e4d1ba492a4e1ccb3b7b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b2bb5ce61c44fe19f0bcb99287e9589","placeholder":"​","style":"IPY_MODEL_7aa2175f4d1546d39115845a928c8383","value":"Loading checkpoint shards:  25%"}},"2770311ddfe34125a6ecab641973cf5b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_fada0a18493c49e2858693d7368aa5f3","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_57d2054352cb40698ea8397bf7e7db38","value":1}},"26d085f232fa438babf3af19f7e55fc3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5c6c6561dec43c19312bd4a99647a50","placeholder":"​","style":"IPY_MODEL_5aa7c83c7e304329b50a312ea8ca353c","value":" 1/4 [00:22&lt;01:07, 22.60s/it]"}},"993307cbf2bd4a9f8a7c00dbcd121f9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b2bb5ce61c44fe19f0bcb99287e9589":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7aa2175f4d1546d39115845a928c8383":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fada0a18493c49e2858693d7368aa5f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57d2054352cb40698ea8397bf7e7db38":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e5c6c6561dec43c19312bd4a99647a50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5aa7c83c7e304329b50a312ea8ca353c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# META LLAMA 3.1  \n","\n","# by ---  \"AD ACADEMY\" - AI for Aam Janta\n","\n","Mentor - Dr Ayan Debnath, IIT Delhi + Harvard university Alumni\n","\n","LinkedIn: [dr_ayan_debnath](https://www.linkedin.com/in/ayan-debnath/)\n","\n","YouTube:[AD ACADEMY AI](https://www.youtube.com/@ad_academy)\n","\n","Topic: Llama 3.1 implementation using Hugging Face\n","\n","class on 25th July 2024"],"metadata":{"id":"qTSo9bI_Lw7n"}},{"cell_type":"markdown","source":["### Download Llama3.1 model from Hugging Face\n","\n","link: https://huggingface.co/collections/meta-llama/llama-31-669fc079a0c406a149a5738f"],"metadata":{"id":"9-C_shsNCISJ"}},{"cell_type":"markdown","source":["# Steps:\n","\n","\n","\n","1.   Importing Hugging Face library\n","2.   Access token from HuggingFace to download model\n","3.   Using / build Pipeline to call LLM\n","4.   Generate text\n","\n"],"metadata":{"id":"J7MUcyS-L_zC"}},{"cell_type":"markdown","source":["# install Python packages"],"metadata":{"id":"a4hB6Cr2EZ9w"}},{"cell_type":"code","source":["!pip install transformers\n","!pip install torch\n","!pip install transformers huggingface_hub"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"oyRCfnfrCoI4","executionInfo":{"status":"ok","timestamp":1721908798341,"user_tz":-330,"elapsed":14377,"user":{"displayName":"Ayan Debnath","userId":"06573521543200295119"}},"outputId":"bfe6cb4e-96ea-480b-8f05-85d0711b2393"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n","Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.23.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n","Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n"]}]},{"cell_type":"markdown","source":["## Import Libraries"],"metadata":{"id":"cD8AKgrKEN-k"}},{"cell_type":"code","source":["import torch\n","import os\n","import json\n","import transformers\n","from transformers import pipeline\n","from huggingface_hub import hf_hub_download, login\n","from transformers import AutoModel, AutoTokenizer, LlamaConfig"],"metadata":{"id":"8L0SdQkBERx8","executionInfo":{"status":"ok","timestamp":1721908818513,"user_tz":-330,"elapsed":20175,"user":{"displayName":"Ayan Debnath","userId":"06573521543200295119"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# Access Token"],"metadata":{"id":"mmPaSZCXh8_y"}},{"cell_type":"markdown","source":["\n","\n","1.   Visit repo: meta-llama/Meta-Llama-3.1-8B-Instruct.\n","2.   Read and accept the license. Once your request is approved, you'll be granted access to all Llama 3.1 models as well as previous versions. Note that requests used to take up to one hour to get processed.\n","\n","\n"],"metadata":{"id":"_Yn_IUUIikPC"}},{"cell_type":"code","source":["# Set environment variables for Hugging Face token\n","os.environ['HF_TOKEN'] = \"***\"\n","os.environ['HUGGINGFACEHUB_API_TOKEN'] = \"****\"\n","\n","# Log in using the token from environment variables\n","huggingface_token = os.environ.get('HF_TOKEN')\n","login(token=huggingface_token)\n","\n","# Define model name\n","model_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n","\n","# Download the configuration file\n","config_path = hf_hub_download(repo_id=model_name, filename=\"config.json\", use_auth_token=True)\n","\n","# Load and adjust the configuration\n","with open(config_path, 'r') as f:\n","    config_data = json.load(f)\n","\n","# Modify the `rope_scaling` field\n","if 'rope_scaling' in config_data and isinstance(config_data['rope_scaling'], dict):\n","    config_data['rope_scaling'] = {\n","        'type': 'linear',  # Replace 'default' with the correct type if known\n","        'factor': config_data['rope_scaling'].get('factor', 1.0)\n","    }\n","\n","# Save the modified configuration locally\n","modified_config_path = \"modified_config.json\"\n","with open(modified_config_path, 'w') as f:\n","    json.dump(config_data, f)\n","\n","# Load the modified configuration\n","config = LlamaConfig.from_json_file(modified_config_path)\n","\n","# Load the tokenizer and model with the modified configuration\n","tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=True)\n","model = AutoModel.from_pretrained(model_name, config=config, use_auth_token=True)\n","\n","# Now you can use the model and tokenizer as needed"],"metadata":{"id":"jbKcSPehDj9W","colab":{"base_uri":"https://localhost:8080/","height":230,"referenced_widgets":["0bb05a9288e447388546935dc9e297aa","7d855e4f146e4d1ba492a4e1ccb3b7b2","2770311ddfe34125a6ecab641973cf5b","26d085f232fa438babf3af19f7e55fc3","993307cbf2bd4a9f8a7c00dbcd121f9c","0b2bb5ce61c44fe19f0bcb99287e9589","7aa2175f4d1546d39115845a928c8383","fada0a18493c49e2858693d7368aa5f3","57d2054352cb40698ea8397bf7e7db38","e5c6c6561dec43c19312bd4a99647a50","5aa7c83c7e304329b50a312ea8ca353c"]},"outputId":"06ee667b-bb29-46e3-c305-cb28ed088570"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n","Token is valid (permission: fineGrained).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py:778: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n","  warnings.warn(\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:469: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bb05a9288e447388546935dc9e297aa"}},"metadata":{}}]},{"cell_type":"code","source":["model(\"Hey tell me about Sachin tendulkar\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"YukATIsjhlZB","executionInfo":{"status":"ok","timestamp":1721904851181,"user_tz":-330,"elapsed":526,"user":{"displayName":"Ayan Debnath","userId":"06573521543200295119"}},"outputId":"accf989a-66ff-418b-e3c5-49a5a089f3ab"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"Sachin Tendulkar, often referred to as the Little Master or Master Blaster, is a former Indian cricketer widely regarded as one of the greatest batsmen in the history of cricket. Born on April 24, 1973, in Mumbai, India, Tendulkar made his debut for the Indian national team at the age of 16. Over a career spanning 24 years, he set numerous records, including being the highest run-scorer in both Test and One Day International (ODI) cricket. Tendulkar is the only player to have scored 100 international centuries and the first to reach 200 runs in a single ODI innings. He played a crucial role in India's 2011 World Cup victory and has received numerous awards, including the Bharat Ratna, India's highest civilian award. His dedication, skill, and sportsmanship have made him an icon both in India and globally.\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["# Download model\n","\n","To download the original native weights to use with this repo, click on the \"Files and versions\" tab and download the contents of the original folder. You can also download them from the command line if you pip install huggingface-hub:\n"],"metadata":{"id":"RRwcA6wai5T7"}},{"cell_type":"code","source":["huggingface-cli download meta-llama/Meta-Llama-3.1-8B-Instruct --include \"original/*\" --local-dir meta-llama/Meta-Llama-3.1-8B-Instruct\n"],"metadata":{"id":"7zNf916mi3nE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"NFEiT2l78jEj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n","\n","llama_model = pipeline(\n","  \"text-generation\",\n","  model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n","  model_kwargs={\"torch_dtype\": torch.bfloat16},\n","  device=\"cuda\",\n",")"],"metadata":{"id":"ucaHxy-tj51X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Experiment"],"metadata":{"id":"Mm2CRwUNZIyU"}}]}